{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOnbDn3oJQGz+5tiw8HVIN/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dvwinck/bilu/blob/main/RDV_moleza.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install requests beautifulsoup4"
      ],
      "metadata": {
        "id": "1QlwZjwmVBQS",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from google.colab import files  # Importação explícita\n",
        "import os\n",
        "import zipfile\n",
        "import time\n",
        "from datetime import datetime\n",
        "import shutil\n",
        "import re\n",
        "\n",
        "# Constantes\n",
        "_SLEEP_TIME = 1\n",
        "NF_DIR = \"NF\"\n",
        "\n",
        "# Função para limpar pastas\n",
        "def limpar_pastas():\n",
        "    if os.path.exists(NF_DIR):\n",
        "        shutil.rmtree(NF_DIR)\n",
        "    os.makedirs(NF_DIR, exist_ok=True)\n",
        "\n",
        "def remover_caracteres_especiais(texto):\n",
        "    # Substitui caracteres que não sejam letras, números ou espaço por uma string vazia\n",
        "    return re.sub(r\"[^a-zA-Z0-9\\s:/]\", \"\", texto)\n",
        "\n",
        "# Função para obter os dados do cupom\n",
        "def obter_dados_cupom(qrcode_url, sequencial):\n",
        "    try:\n",
        "        # Configurar headers para simular navegador\n",
        "        headers = {\n",
        "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.1 Safari/537.36\",\n",
        "            \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8\",\n",
        "            \"Accept-Language\": \"pt-BR,pt;q=0.9,en-US;q=0.8,en;q=0.7\",\n",
        "            \"Accept-Encoding\": \"gzip, deflate, br\",\n",
        "            \"Connection\": \"keep-alive\",\n",
        "            \"Upgrade-Insecure-Requests\": \"1\",\n",
        "            \"Sec-Fetch-Dest\": \"document\",\n",
        "            \"Sec-Fetch-Mode\": \"navigate\",\n",
        "            \"Sec-Fetch-Site\": \"none\",\n",
        "            \"Sec-Fetch-User\": \"?1\",\n",
        "            \"Cache-Control\": \"max-age=0\",\n",
        "        }\n",
        "\n",
        "        # Fazer a requisição\n",
        "        response = requests.get(qrcode_url, headers=headers)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        # Salvar o HTML da nota fiscal\n",
        "        arquivo_nf = f\"{NF_DIR}/NF{sequencial}.html\"\n",
        "        with open(arquivo_nf, \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(response.text)\n",
        "\n",
        "        # Parsear o HTML\n",
        "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "\n",
        "        # Extrair valor total do cupom\n",
        "        valor_element = soup.find(\"span\", class_=\"totalNumb txtMax\")\n",
        "        valor_total = valor_element.text.strip() if valor_element else \"Não encontrado\"\n",
        "\n",
        "        # Extrair data e hora de emissão\n",
        "        emissao_element = soup.find(\"strong\", string=\" Emissão: \")\n",
        "        if emissao_element:\n",
        "            emissao_data = emissao_element.next_sibling\n",
        "            emissao_data_limpo = remover_caracteres_especiais(emissao_data)\n",
        "            partes = emissao_data_limpo.split(\" \")\n",
        "            data = partes[0].strip()\n",
        "            hora = partes[1].strip()\n",
        "            print(f\" DATA:{data} HORA:{hora}\")\n",
        "        else:\n",
        "            data = \"N/A\"\n",
        "            hora = \"N/A\"\n",
        "\n",
        "        return {\n",
        "            \"sequencial\": sequencial,\n",
        "            \"data\": data,\n",
        "            \"hora\": hora,\n",
        "            \"valor_total\": valor_total,\n",
        "            \"link\": qrcode_url,\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return {\n",
        "            \"sequencial\": sequencial,\n",
        "            \"data\": \"N/A\",\n",
        "            \"hora\": \"N/A\",\n",
        "            \"valor_total\": \"N/A\",\n",
        "            \"link\": qrcode_url,\n",
        "            \"erro\": str(e),\n",
        "        }\n",
        "\n",
        "# Função para processar a lista de links\n",
        "def processar_lista_links(lista_links, salvar_arquivo=\"resultados.html\", salvar_csv=\"resultados.csv\"):\n",
        "    # Limpar pastas no início do processamento\n",
        "    limpar_pastas()\n",
        "\n",
        "    resultados = []\n",
        "\n",
        "    for idx, link in enumerate(lista_links, start=1):\n",
        "        print(f\"Processando: {link}\")\n",
        "        resultado = obter_dados_cupom(link, idx)\n",
        "        resultados.append(resultado)\n",
        "        time.sleep(_SLEEP_TIME)\n",
        "\n",
        "    salvar_resultados_em_arquivo(resultados, salvar_arquivo)\n",
        "    salvar_resultados_em_csv(resultados, salvar_csv)\n",
        "    compactar_relatorio(salvar_arquivo, salvar_csv)\n",
        "\n",
        "# Função para salvar resultados em HTML\n",
        "def salvar_resultados_em_arquivo(resultados, nome_arquivo):\n",
        "    total_valor = sum(\n",
        "        float(r[\"valor_total\"].replace(\",\", \".\"))\n",
        "        for r in resultados\n",
        "        if r.get(\"valor_total\") and r[\"valor_total\"].replace(\",\", \".\").replace(\".\", \"\", 1).isdigit()\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "    with open(nome_arquivo, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(\"\"\"\n",
        "        <!DOCTYPE html>\n",
        "        <html lang=\"en\">\n",
        "        <head>\n",
        "            <meta charset=\"UTF-8\">\n",
        "            <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
        "            <title>Extrato dos Cupons</title>\n",
        "            <link href=\"https://cdn.jsdelivr.net/npm/bootstrap@5.3.0-alpha3/dist/css/bootstrap.min.css\" rel=\"stylesheet\">\n",
        "        </head>\n",
        "        <body class=\"bg-light\">\n",
        "            <div class=\"container mt-5\">\n",
        "                <h1 class=\"text-center text-primary mb-4\">Extrato dos Cupons</h1>\n",
        "                <table class=\"table table-striped table-hover table-bordered\">\n",
        "                    <thead class=\"table-dark\">\n",
        "        \"\"\")\n",
        "        f.write(\"<tr><th>Sequência</th><th>Data</th><th>Hora</th><th>Valor Total</th><th>Erro</th><th>Link</th></tr></thead><tbody>\")\n",
        "        for r in resultados:\n",
        "            f.write(f\"<tr><td>{r['sequencial']}</td><td>{r['data']}</td><td>{r['hora']}</td><td>{r['valor_total']}</td><td>{r.get('erro', 'N/A')}</td><td><a href='{r['link']}'>Abrir</a></td></tr>\")\n",
        "        f.write(\"</tbody></table>\")\n",
        "\n",
        "        f.write(f\"\"\"\n",
        "        <div style=\"margin-top: 20px; text-align: right;\">\n",
        "            <h4><strong>Total Geral: R$ {total_valor:.2f}</strong></h4>\n",
        "        </div>\n",
        "        \"\"\")\n",
        "        f.write(f\"</body></html>\")\n",
        "\n",
        "# Função para salvar resultados em CSV\n",
        "def salvar_resultados_em_csv(resultados, nome_csv):\n",
        "    with open(nome_csv, mode=\"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
        "        writer = csv.writer(csvfile)\n",
        "        writer.writerow([\"Sequência\", \"Data\", \"Hora\", \"Valor Total\", \"Erro\", \"Link\"])\n",
        "        for r in resultados:\n",
        "            writer.writerow([r[\"sequencial\"], r[\"data\"], r[\"hora\"], r[\"valor_total\"], r.get(\"erro\", \"N/A\"), r[\"link\"]])\n",
        "\n",
        "# Função para compactar arquivos\n",
        "def compactar_relatorio(relatorio_arquivo, relatorio_csv):\n",
        "    zip_filename = \"relatorio_e_notas.zip\"\n",
        "    with zipfile.ZipFile(zip_filename, \"w\", zipfile.ZIP_DEFLATED) as zf:\n",
        "        zf.write(relatorio_arquivo)\n",
        "        zf.write(relatorio_csv)\n",
        "        for root, dirs, files_ in os.walk(NF_DIR):\n",
        "            for file in files_:\n",
        "                zf.write(os.path.join(root, file))\n",
        "    # Corrigindo o erro de download\n",
        "    files.download(zip_filename)\n",
        "\n",
        "# Função para carregar links de arquivo\n",
        "def carregar_links_de_arquivo():\n",
        "    print(\"Carregue um arquivo contendo os links:\")\n",
        "    uploaded = files.upload()\n",
        "    for filename in uploaded.keys():\n",
        "        with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
        "            return f.read().splitlines()\n",
        "\n",
        "# Executar o programa\n",
        "lista_links = carregar_links_de_arquivo()\n",
        "data_hora_atual = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
        "processar_lista_links(lista_links, f\"relatorio_cupons_{data_hora_atual}.html\", f\"relatorio_cupons_{data_hora_atual}.csv\")\n"
      ],
      "metadata": {
        "id": "O-5ZQc1A0E_R"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}